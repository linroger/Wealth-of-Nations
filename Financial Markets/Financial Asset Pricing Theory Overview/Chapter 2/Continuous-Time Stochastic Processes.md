---
tags:
  - '#brownian_motion'
  - '#diffusion_processes'
  - '#financial_modeling'
  - '#geometric_brownian_motion'
  - '#ito_lemma'
  - '#ito_process'
  - '#jump_processes'
  - '#stochastic_integrals'
  - '#stochastic_processes'
  - '#wiener_process'
---
# 2.6 Continuous-time stochastic processes  

# 2.6.1 Brownian motions  

In the continuous-time asset pricing models we will consider in this book, the basic uncertainty in the economy is represented by the evolution of a standard Brownian motion. A (one-dimensional) stochastic process $z~=~(z_{t})_{t\in[0,T]}$ is called a standard Brownian motion, if it satisfies the following conditions:  

(i) $z_{\mathrm{0}}=0$ (ii) for all. $t,t^{\prime}\geq0$ with $t<t^{\prime}$ .. $z_{t^{\prime}}-z_{t}\sim N(0,t^{\prime}-t)$ [normally distributed increments], (ii) for all $0\leq t_{0}<t_{1}<\dots<t_{n}$ , the random variables. $z_{t_{1}}-z_{t_{0}}$ , ..., $z_{t_{n}}-z_{t_{n-1}}$ are mutually independent [independent increments], (iv) $z$ has continuous sample paths.  

The first three conditions are equivalent to the discrete-time case studied above. We can informally. think of $d z_{t}\approx z_{t+d t}-z_{t}\sim N(0,d t)$ as an exogenous shock to the economy at time. $t$ . The state space $\Omega$ is in this case the (infinite) set of all paths of the standard Brownian motion $z$ . The information filtration $(\mathcal{F}_{t})_{t\in[0,T]}$ is generated by the standard Brownian motion. $z$ in the sense that, for each $t$ $\mathcal{F}_{t}$ is the smallest $\sigma$ -algebra on which the random variable. $z_{t}$ is measurable. The probability measure $\mathbb{P}$ is fixed by the normality assumption.  

Any continuous-time stochastic process $X~=~(X_{t})_{t\in[0,T]}$ in the financial models in this book will be defined in terms of the standard Brownian motion by an initial constant value $X_{0}$ and an equation of the form  

$$
d X_{t}=\mu_{t}d t+\sigma_{t}d z_{t}.
$$  

Here $\mu_{t}$ and $\sigma_{t}$ are known at time $t$ (measurable with respect to $\mathcal{F}_{t}$ ) but may depend on $X_{s}$ and $z_{s}$ for $s\leq t$ . We can informally think of $d X_{t}$ as the increment. $X_{t+d t}-X_{t}$ over the "instant" (of length $d t$ ) following time $t$ . Since $d{\boldsymbol{z}}_{t}$ has mean zero and variance $d t$ , we can informally compute the conditional mean and variance of $d X_{t}$ as  

$$
\operatorname{E}_{t}[d X_{t}]=\mu_{t}d t,\qquad\operatorname{Var}_{t}[d X_{t}]=\sigma_{t}^{2}d t.
$$  

Therefore we can interpret $\mu_{t}$ and $\sigma_{t}^{2}$ as the conditional mean and conditional variance of the. change in the value of the process per time unit. The properties of the process $X$ will depend on the specification of $\mu_{t}$ and $\sigma_{t}$ . We will be more formal and give examples below.  

The standard Brownian motion is basically the continuous-time version of a random walk with initial value 0. The standard Brownian motion is a Markov process because the increment from today to any future point in time is independent of the history of the process. The standard Brownian motion is also a martingale since the expected change in the value of the process is zero. The name Brownian motion is in honor of the Scottish botanist Robert Brown, who in 1828 observed the apparently random movements of pollen submerged in water. The often used name Wiener process is due to Norbert Wiener, who in the 1920s was the first to show the existence of a stochastic process with these properties and who developed a mathematically rigorous analysis of the process. As early as in the year 1900, the standard Brownian motion was used in a model for stock price movements by the French researcher Louis Bachelier, who derived the first option pricing formula.  

The defining characteristics of a standard Brownian motion look very nice, but they have some drastic consequences. It can be shown that the sample paths of a standard Brownian motion are nowhere differentiable, which broadly speaking means that the sample paths bend at all points in time and are therefore strictly speaking impossible to illustrate. However, one can get an idea of the sample paths by simulating the values of the process at different times. If $\varepsilon_{1},\ldots,\varepsilon_{n}$ are independent draws from a standard $N(0,1)$ distribution, we can simulate the value of the standard Brownian motion at time $0\equiv t_{0}<t_{1}<t_{2}<\cdots<t_{n}$ as follows:  

$$
z_{t_{i}}=z_{t_{i-1}}+\varepsilon_{i}{\sqrt{t_{i}-t_{i-1}}},\quad i=1,\ldots,n.
$$  

With more time points and hence shorter intervals we get a more realistic impression of the sample paths of the process. Figure 2.5 shows a simulated sample path for a standard Brownian motion over the interval $[0,1]$ based on a partition of the interval into 200 subintervals of equal length.1. Note that since a normally distributed random variable can take on infinitely many values, a. standard Brownian motion has infinitely many sample paths that each has a zero probability of. occurring. The figure shows just one possible sample path. Note that the picture resembles typical stock price charts.  

![](acc192020f69e3747bc620596e7b351894cfbbee7311f58375aa4faf0f0511ac.jpg)  
Figure 2.5: A simulated sample path of a standard Brownian motion based on 200 subintervals.  

Another property of a standard Brownian motion is that the expected length of the sample path over any future time interval (no matter how short) is infinite. In addition, the expected number of times a standard Brownian motion takes on any given value in any given time interval is also infinite. Intuitively, these properties are due to the fact that the size of the increment of a standard Brownian motion over an interval of length $\Delta t$ is proportional to $\sqrt{\Delta t}$ , in the sense that the standard deviation of the increment equals $\sqrt{\Delta t}$ . When $\Delta t$ is close to zero, $\sqrt{\Delta t}$ is significantly larger than $\Delta t$ , so the changes are large relative to the length of the time interval over which the changes are measured.  

The expected change in an object described by a standard Brownian motion equals zero and the variance of the change over a given time interval equals the length of the interval. This can easily be generalized. As before let $z=(z_{t})_{t\geq0}$ be a one-dimensional standard Brownian motion and define a new stochastic process $X=(X_{t})_{t\geq0}$ by  

$$
X_{t}=X_{0}+\mu t+\sigma z_{t},\quad t\geq0,
$$  

where $X_{0}$ $\mu$ , and $\sigma$ are constants. The constant $X_{0}$ is the initial value for the process $X$ .It follows from the properties of the standard Brownian motion that, seen from time $0$ , the value $X_{t}$ is normally distributed with mean $\mu t$ and variance $\sigma^{2}t$ , i.e. $X_{t}\sim N(X_{0}+\mu t,\sigma^{2}t)$  

The change in the value of the process between two arbitrary points in time $t$ and $t^{\prime}$ ,  where $t<t^{\prime}$ , is given by  

$$
X_{t^{\prime}}-X_{t}=\mu(t^{\prime}-t)+\sigma(z_{t^{\prime}}-z_{t}).
$$  

The change over an infinitesimally short interval $[t,t+\Delta t]$ with $\Delta t\rightarrow0$ is often written as.  

$$
d X_{t}=\mu d t+\sigma d z_{t},
$$  

where $d{\boldsymbol{z}}_{t}$ can loosely be interpreted as a. $N(0,d t)$ -distributed random variable. To give this a. precise mathematical meaning, it must be interpreted as a limit of the expression  

$$
X_{t+\Delta{t}}-X_{t}=\mu\Delta{t}+\sigma(z_{t+\Delta{t}}-z_{t})
$$  

for $\Delta t\rightarrow0$ . The process $X$ is called a generalized Brownian motion or a generalized Wiener. process. This is basically the continuous-time version of a random walk with drift. The parameter $\mu$ reflects the expected change in the process per unit of time and is called the drift rate or simply the drift of the process. The parameter $\sigma$ reflects the uncertainty about the future values of the. process. More precisely, $\sigma^{2}$ reflects the variance of the change in the process per unit of time and. is often called the variance rate of the process.. $\sigma$ is a measure for the standard deviation of the change per unit of time and is referred to as the volatility of the process..  

A generalized Brownian motion inherits many of the characteristic properties of a standard Brownian motion. For example, also a generalized Brownian motion is a Markov process, and the sample paths of a generalized Brownian motion are also continuous and nowhere differentiable. However, a generalized Brownian motion is not a martingale unless $\mu=0$ . The sample paths can be simulated by choosing time points $0\equiv t_{0}<t_{1}<\cdots<t_{n}$ and iteratively computing  

$$
X_{t_{i}}=X_{t_{i-1}}+\mu(t_{i}-t_{i-1})+\varepsilon_{i}\sigma\sqrt{t_{i}-t_{i-1}},\quad i=1,\dots,n,
$$  

where $\varepsilon_{1},\ldots,\varepsilon_{n}$ are independent draws from a standard normal distribution. Figure 2.6 show simulated sample paths for two different values of $\sigma$ but the same $\mu$ . The paths are drawn using. the same sequence of random numbers $\varepsilon_{i}$ so that they are directly comparable. The straight line. represent the deterministic trend of the process, which corresponds to imposing the condition $\sigma=0$ and hence ignoring the uncertainty. The parameter. $\mu$ determines the trend, and the parameter $\sigma$ determines the size of the fluctuations around the trend..  

If the parameters $\mu$ and $\sigma$ are allowed to be time-varying in a deterministic way, the process $X$ is said to be a time-inhomogeneous generalized Brownian motion. In differential terms such a process can be written as defined by  

$$
d X_{t}=\mu(t)d t+\sigma(t)d z_{t}.
$$  

Over a very short interval $[t,t+\Delta t]$ the expected change is approximately $\mu(t)\Delta t$ , and the variance of the change is approximately $\sigma(t)^{2}\Delta t$ . More precisely, the increment over any interval $[t,t^{\prime}]$ is given by  

$$
X_{t^{\prime}}-X_{t}=\int_{t}^{t^{\prime}}\mu(u)d u+\int_{t}^{t^{\prime}}\sigma(u)d z_{u}.
$$  

The last integral is a so-called stochastic integral, which we will define (although not rigorously) and describe in a later section. There we will also state a theorem, which implies that, seen from time $t$ , the integral $\begin{array}{r l}{\int_{t}^{t^{\prime}}\sigma(u)d z_{u}}\end{array}$ is a normally distributed random variable with mean zero and. variance $\begin{array}{r}{\int_{t}^{t^{\prime}}\sigma(u)^{2}d u}\end{array}$  

# 2.6.2 Diffusion processes  

For both standard Brownian motions and generalized Brownian motions, the future value is normally distributed and can therefore take on any real value, i.e. the value space is equal to. $\mathbb{R}$  

![](6d6b0041ee47bb759cac78b6fe80ca2d515cc36fb2366489b7910b5fc56a5907.jpg)  
Figure 2.6: Simulation of a generalized Brownian motion with $\mu=0.2$ and $\sigma=0.5$ or $\sigma=1.0$ .The straight line shows the trend corresponding to $\sigma=0$ . The simulations are based on 200 subintervals.  

Many economic variables can only have values in a certain subset of. $\mathbb{R}$ .For example, prices of financial assets with limited liability are non-negative. The evolution in such variables cannot be well represented by the stochastic processes studied so far. In many situations we will instead use so-called diffusion processes.  

A (one-dimensional) diffusion process is a stochastic process $X=(X_{t})_{t\geq0}$ for which the change. over an infinitesimally short time interval. $[t,t+d t]$ can be written as  

$$
d X_{t}=\mu(X_{t},t)d t+\sigma(X_{t},t)d z_{t},
$$  

where $z$ is a standard Brownian motion, but where the drift $\mu$ and the volatility $\sigma$ are now functions of time and the current value of the process.2 This expression generalizes (2.3), where $\mu$ and $\sigma$ were assumed to be constants, and (2.4), where $\mu$ and $\sigma$ were functions of time only. An equation like (2.6), where the stochastic process enters both sides of the equality, is called a stochastic differential equation. Hence, a diffusion process is a solution to a stochastic differential equation.  

If both functions $\mu$ and $\sigma$ are independent of time, the diffusion is said to be time-homogeneous, otherwise it is said to be time-inhomogeneous. For a time-homogeneous diffusion process, the distribution of the future value will only depend on the current value of the process and how far into the future we are looking - not on the particular point in time we are standing at. For example, the distribution of $X_{t+\delta}$ given $X_{t}=x$ will only depend on $X$ and $\delta$ , but not on $t$ This is not the case for a time-inhomogeneous diffusion, where the distribution will also depend on $t$  

In the expression (2.6) one may think of. $d{\boldsymbol{z}}_{t}$ as being $N(0,d t)$ -distributed, so that the mean and. variance of the change over an infinitesimally short interval $[t,t+d t]$ are given by  

$$
 \mathrm{\quad}_{t}^{}[d X_{t}]=\mu(X_{t},t)d t,\qquad\mathrm{Var}_{t}[d X_{t}]=\sigma(X_{t},t)^{2}d t.
$$  

To be more precise, the change in a diffusion process over any interval $[t,t^{\prime}]$ is  

$$
X_{t^{\prime}}-X_{t}=\int_{t}^{t^{\prime}}\mu(X_{u},u)d u+\int_{t}^{t^{\prime}}\sigma(X_{u},u)d z_{u}.
$$  

Here the integrand of the first integral. $\begin{array}{r}{\int_{t}^{t^{\prime}}\mu(X_{u},u)d u}\end{array}$ depends on the values $X_{u}$ for $u\in[t,t^{\prime}]$ which are generally unknown at time. $t$ . It is therefore natural to define the integral. $\begin{array}{r}{\int_{t}^{t^{\prime}}\mu(X_{u},u)d u}\end{array}$ as the random variable which in state. $\omega\in\Omega$ has the value $\begin{array}{r}{\int_{t}^{t^{\prime}}\mu(X_{u}(\omega),u)d u}\end{array}$ , which is now just the integration of a real-valued function of time. The other integral $\begin{array}{r}{\int_{t}^{t^{\prime}}\sigma(X_{u},u)d z_{u}}\end{array}$ is a so-called stochastic integral, which we will discuss in Section 2.6.5.  

We will often use the informal and intuitive differential notation (2.6). The drift rate $\mu(X_{t},t)$ and the variance rate $\sigma(X_{t},t)^{2}$ are really the limits  

$$
\begin{array}{r}{\mu(X_{t},t)=\displaystyle\operatorname*{lim}_{\Delta t\to0}\frac{\operatorname{E}_{t}\left[X_{t+\Delta t}-X_{t}\right]}{\Delta t},}\ {\sigma(X_{t},t)^{2}=\displaystyle\operatorname*{lim}_{\Delta t\to0}\frac{\operatorname{Var}_{t}\left[X_{t+\Delta t}-X_{t}\right]}{\Delta t}.}\end{array}
$$  

A diffusion process is a Markov process as can be seen from (2.6), since both the drift and the volatility only depend on the current value of the process and not on previous values. A diffusion process is not a martingale, unless the drift $\mu(X_{t},t)$ is zero for all $X_{t}$ and $t$ . A diffusion process will have continuous, but nowhere differentiable sample paths. The value space for a diffusion process and the distribution of future values will depend on the functions $\mu$ and $\sigma$ . In Section 2.6.7 we will an example of a diffusion process often used in financial modeling, the so-called geometric Brownian motion. Other diffusion processes will be used in later chapters.  

# 2.6.3 Ito processes  

It is possible to define even more general continuous-path processes than those in the class of diffusion processes. A (one-dimensional) stochastic process. $X_{t}$ is said to be an Ito process, if the. local increments are on the form  

$$
d X_{t}=\mu_{t}d t+\sigma_{t}d z_{t},
$$  

where the drift $\mu$ and the volatility. $\sigma$ themselves are stochastic processes. A diffusion process is. the special case where the values of the drift. $\mu_{t}$ and the volatility. $\sigma_{t}$ are given as functions of $t$ and $X_{t}$ . For a general Ito process, the drift and volatility may also depend on past values of the $X$ process and also on past and current values of other adapted processes. It follows that Ito. processes are generally not Markov processes. They are generally not martingales either, unless $\mu_{t}$ is identically equal to zero (and $\sigma_{t}$ satisfies some technical conditions). The processes $\mu$ and $\sigma$ must satisfy certain regularity conditions for the. $X$ process to be well-defined. We will refer. the reader to Oksendal (1998, Ch. 4) for these conditions. The expression (2.8) gives an intuitive understanding of the evolution of an Ito process, but it is more precise to state the evolution in the integral form  

$$
X_{t^{\prime}}-X_{t}=\int_{t}^{t^{\prime}}\mu_{u}d u+\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}.
$$  

Again the first integral can be defined "state-by-state' and the second integral is a stochastic integral.  

# 2.6.4 Jump processes  

Above we have focused on processes having sample paths that are continuous functions of time,. so that one can depict the evolution of the process by a continuous curve. Stochastic processes which have sample paths with discontinuities (jumps) also exist. The jumps of such processes are often modeled by Poisson processes or related processes. It is well-known that large, sudden movements in financial variables occur from time to time, for example in connection with stock market crashes. There may be many explanations of such large movements, for example a large unexpected change in the productivity in a particular industry or the economy in general, perhaps due to a technological break-through. Another source of sudden, large movements is changes in the political or economic environment such as unforseen interventions by the government or central bank. Stock market crashes are sometimes explained by the bursting of a bubble (which does not necessarily conflict with the usual assumption of rational investors). Whether such sudden, large movements can be explained by a sequence of small continuous movements in the same direction or jumps have to be included in the models is an empirical question, which is still open. While jump processes may be relevant for many purposes, they are also more difficult to deal with than processes with continuous sample paths so that it will probably be best to study models without jumps first. This book will only address continuous-path processes. An overview of financial models with jump processes is given by Cont and Tankov (2004)..  

# 2.6.5 Stochastic integrals  

In (2.7) and (2.9) and similar expressions a term of the form. $\begin{array}{r}{\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}}\end{array}$ appears. An integral of this type is called a stochastic integral or an Ito integral. For given. $t<t^{\prime}$ , the stochastic integral. $\begin{array}{r}{\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}}\end{array}$ is a random variable. Assuming that. $\sigma_{u}$ is known at time $u$ , the value of the integral. becomes known at time. $t^{\prime}$ . The process $\sigma$ is called the integrand. The stochastic integral can be. defined for very general integrands. The simplest integrands are those that are piecewise constant. Assume that there are points in time. $t\equiv t_{0}<t_{1}<\cdots<t_{n}\equiv t^{\prime}$ , so that $\sigma_{u}$ is constant on each subinterval $[t_{i},t_{i+1})$ . The stochastic integral is then defined by  

$$
\int_{t}^{t^{'}}\sigma_{u}d z_{u}=\sum_{i=0}^{n-1}\sigma_{t_{i}}\left(z_{t_{i+1}}-z_{t_{i}}\right).
$$  

If the integrand process $\sigma$ is not piecewise constant, there will exist a sequence of piecewise constant processes $\sigma^{(1)},\sigma^{(2)},\ldots$ , which converges to $\sigma$ . For each of the processes $\sigma^{(m)}$ , the integral $\begin{array}{r}{\int_{t}^{t^{\prime}}\sigma_{u}^{(m)}d z_{u}}\end{array}$ is defined as above. The integral $\begin{array}{r}{\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}}\end{array}$ is then defined as a limit of the integals of the approximating processes:  

$$
\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}=\operatorname*{lim}_{m\to\infty}\int_{t}^{t^{\prime}}\sigma_{u}^{(m)}d z_{u}.
$$  

We will not discuss exactly how this limit is to be understood and which integrand processes we can allow. Again the interested reader is referred to $\boldsymbol{\mathrm{\Omega}}$ ksendal (1998). The distribution of the integral  

$\begin{array}{r}{\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}}\end{array}$ will, of course, depend on the integrand process and can generally not be completely characterized, but the following theorem gives the mean and the variance of the integral:  

Theorem 2.2 The stochastic integral $\begin{array}{r}{\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}}\end{array}$ has the following properties:  

$$
\begin{array}{c}{{\displaystyle\mathrm{E}_{t}\left[\int_{t}^{t^{'}}\sigma_{u}~d z_{u}\right]=0,}}\ {{\displaystyle\mathrm{Var}_{t}\left[\int_{t}^{t^{'}}\sigma_{u}~d z_{u}\right]=\int_{t}^{t^{'}}\mathrm{E}_{t}[\sigma_{u}^{2}]~d u.}}\end{array}
$$  

Proof: Suppose that $\sigma$ is piecewise constant and divide the interval $[t,t^{\prime}]$ into subintervals defined by the time points $t\equiv t_{0}<t_{1}<\cdots<t_{n}\equiv t^{\prime}$ so that $\sigma$ is constant on each subinterval $[t_{i},t_{i+1})$ with a value $\sigma_{t_{i}}$ which is known at time $t_{i}$ . Then  

$$
\operatorname{E}_{t}\left[\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}\right]=\sum_{i=0}^{n-1}\operatorname{E}_{t}\left[\sigma_{t_{i}}\left(z_{t_{i+1}}-z_{t_{i}}\right)\right]=\sum_{i=0}^{n-1}\operatorname{E}_{t}\left[\sigma_{t_{i}}\operatorname{E}_{t_{i}}\left[\left(z_{t_{i+1}}-z_{t_{i}}\right)\right]\right]=0,
$$  

using the Law of Iterated Expectations. For the variance we have  

$$
\operatorname{Var}_{t}\left[\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}\right]=\operatorname{E}_{t}\left[\left(\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}\right)^{2}\right]-\left(\operatorname{E}_{t}\left[\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}\right]\right)^{2}=\operatorname{E}_{t}\left[\left(\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}\right)^{2}\right]
$$  

and  

$$
\begin{array}{r l}&{\mathrm{E}_{t}\left[\left(\displaystyle\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}\right)^{2}\right]=\mathrm{E}_{t}\left[\displaystyle\sum_{i=0}^{n-1}\displaystyle\sum_{j=0}^{n-1}\sigma_{t_{i}}\sigma_{t_{j}}\left(z_{t_{i+1}}-z_{t_{i}}\right)\left(z_{t_{j+1}}-z_{t_{j}}\right)\right]}\ &{\qquad=\displaystyle\sum_{i=0}^{n-1}\mathrm{E}_{t}\left[\sigma_{t_{i}}^{2}(z_{t_{i+1}}-z_{t_{i}})^{2}\right]=\displaystyle\sum_{i=0}^{n-1}\mathrm{E}_{t}\left[\sigma_{t_{i}}^{2}\right](t_{i+1}-t_{i})=\displaystyle\int_{t}^{t^{\prime}}\mathrm{E}_{t}[\sigma_{u}^{2}]d u.}\end{array}
$$  

If $\sigma$ is not piecewise constant, we can approximate it by a piecewise constant process and take appropriate limits.  

If the integrand is a deterministic function of time, $\sigma(u)$ , the integral will be normally distributed, so that the following result holds:  

Theorem 2.3 If $z$ is a Brownian motion, and $\sigma(u)$ is a deterministic function of time, the random variable $\begin{array}{r}{\int_{t}^{t^{\prime}}\sigma(u)d z_{u}}\end{array}$ is normally distributed with mean zero and variance $\begin{array}{r}{\int_{t}^{t^{\prime}}\sigma(u)^{2}d u}\end{array}$  

Proof: We present a sketch of the proof. Dividing the interval $[t,t^{\prime}]$ into subintervals defined by.   
the time points $t\equiv t_{0}<t_{1}<\cdots<t_{n}\equiv t^{\prime}$ , we can approximate the integral with the sum.  

$$
\int_{t}^{t^{\prime}}\sigma(u)d z_{u}\approx\sum_{i=0}^{n-1}\sigma(t_{i})\left(z_{t_{i+1}}-z_{t_{i}}\right).
$$  

The increment of the Brownian motion over any subinterval is normally distributed with mean zero and a variance equal to the length of the subinterval. Furthermore, the different terms in the sum are mutually independent. It is well-known that a sum of normally distributed random variables is itself normally distributed, and that the mean of the sum is equal to the sum of the means, which in the present case yields zero. Due to the independence of the terms in the sum, the variance of the sum is also equal to the sum of the variances, i.e.  

$$
\operatorname{Var}_{t}\left[\sum_{i=0}^{n-1}\sigma(t_{i})\left(z_{t_{i+1}}-z_{t_{i}}\right)\right]=\sum_{i=0}^{n-1}\sigma(t_{i})^{2}\operatorname{Var}_{t}\left[z_{t_{i+1}}-z_{t_{i}}\right]=\sum_{i=0}^{n-1}\sigma(t_{i})^{2}(t_{i+1}-t_{i}),
$$  

which is an approximation of the integral. $\begin{array}{r}{\int_{t}^{t^{\prime}}\sigma(u)^{2}d u}\end{array}$ . The result now follows from an appropriate.   
limit where the subintervals shrink to zero length.  

Note that the process $y=(y_{t})_{t\geq0}$ defined by. $\begin{array}{r}{y_{t}=\int_{0}^{t}\sigma_{u}d z_{u}}\end{array}$ is a martingale, since  

$$
\begin{array}{l}{{\displaystyle\mathrm{E}_{t}[y_{t^{\prime}}]=\mathrm{E}_{t}\left[\int_{0}^{t^{\prime}}\sigma_{u}d z_{u}\right]=\mathrm{E}_{t}\left[\int_{0}^{t}\sigma_{u}d z_{u}+\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}\right]}}\ {{\displaystyle=\mathrm{E}_{t}\left[\int_{0}^{t}\sigma_{u}d z_{u}\right]+\mathrm{E}_{t}\left[\int_{t}^{t^{\prime}}\sigma_{u}d z_{u}\right]=\int_{0}^{t}\sigma_{u}d z_{u}=y_{t}},}\end{array}
$$  

so that the expected future value is equal to the current value. More generally $\begin{array}{r}{y_{t}=y_{0}+\int_{0}^{t}\sigma_{u}d z_{u}}\end{array}$ for some constant $y_{0}$ , is a martingale. The converse is also true in the sense that any martingale can be expressed as a stochastic integral. This is the so-called martingale representation theorem:  

Theorem 2.4 Suppose the process $M=\left(M_{t}\right)$ is a martingale with respect to a probability measure under which $z=\left(z_{t}\right)$ is a standard Brownian motion. Then a unique adapted process $\theta=\left(\theta_{t}\right)$ exists such that  

$$
M_{t}=M_{0}+\int_{0}^{t}\theta_{u}d z_{u}
$$  

for all $t$  

For a mathematically more precise statement of the result and a proof, see Oksendal (1998, Thm. 4.3.4).  

Now the stochastic integral with respect to the standard Brownian motion has been defined, we can also define stochastic integrals with respect to other stochastic processes. For example, if $X_{t}$ is a diffusion given by $d X_{t}=\mu(X_{t},t)d t+\sigma(X_{t},t)d z_{t}$ and $\alpha=(\alpha_{t})_{t\in[0,T]}$ is a sufficiently "nice" stochastic process, we can define.  

$$
\int_{0}^{t}\alpha_{u}d X_{u}=\int_{0}^{t}\alpha_{u}\mu(X_{u},u)d u+\int_{0}^{t}\alpha_{u}\sigma(X_{u},u)d z_{u}.
$$  

# 2.6.6 Ito's Lemma  

In continuous-time models a stochastic process for the dynamics of some basic quantity is often.   
taken as given, while other quantities of interest can be shown to be functions of that basic variable.   
To determine the dynamics of these other variables, we shall apply Ito's Lemma, which is basically.   
the chain rule for stochastic processes. We will state the result for a function of a general Ito.   
process, although we will frequently apply the result for the special case of a function of a diffusion process.  

Theorem 2.5 Let $X=(X_{t})_{t\geq0}$ be a real-valued Ito process with dynamics  

$$
d X_{t}=\mu_{t}d t+\sigma_{t}d z_{t},
$$  

where $\mu$ and $\sigma$ are real-valued processes, and. $z$ is a one-dimensional standard Brownian motion.. Let $g(X,t)$ be a real-valued function which is two times continuously differentiable in $X$ and continuously differentiable in. $t$ . Then the process $y=(y_{t})_{t\geq0}$ defined by  

$$
y_{t}=g(X_{t},t)
$$  

is an Ito process with dynamics  

$$
d y_{t}=\left(\frac{\partial g}{\partial t}(X_{t},t)+\frac{\partial g}{\partial X}(X_{t},t)\mu_{t}+\frac{1}{2}\frac{\partial^{2}g}{\partial X^{2}}(X_{t},t)\sigma_{t}^{2}\right)d t+\frac{\partial g}{\partial X}(X_{t},t)\sigma_{t}d z_{t}.
$$  

The proof of Ito's Lemma is based on a Taylor expansion of. $g(X_{t},t)$ combined with appropriate limits, but a formal proof is beyond the scope of this presentation. Once again, we refer to Oksendal. (1998) and similar textbooks. The result can also be written in the following way, which may be easier to remember:  

$$
d y_{t}={\frac{\partial g}{\partial t}}(X_{t},t)d t+{\frac{\partial g}{\partial X}}(X_{t},t)d X_{t}+{\frac{1}{2}}{\frac{\partial^{2}g}{\partial X^{2}}}(X_{t},t)(d X_{t})^{2}.
$$  

Here, in the computation of $(d X_{t})^{2}$ , one must apply the rules $(d t)^{2}=d t\cdot d z_{t}=0$ and $(d z_{t})^{2}=d t$ so that  

$$
(d X_{t})^{2}=(\mu_{t}d t+\sigma_{t}d z_{t})^{2}=\mu_{t}^{2}(d t)^{2}+2\mu_{t}\sigma_{t}d t\cdot d z_{t}+\sigma_{t}^{2}(d z_{t})^{2}=\sigma_{t}^{2}d t.
$$  

The intuition behind these rules is as follows: When $d t$ is close to zero,. $(d t)^{2}$ is far less than. $d t$ and can therefore be ignored. Since $d z_{t}\sim N(0,d t)$ , we get $\operatorname{E}[d t\cdot d z_{t}]=d t\cdot\operatorname{E}[d z_{t}]=0$ and $\mathrm{Var}[d t\cdot d z_{t}]=(d t)^{2}\mathrm{Var}[d z_{t}]=(d t)^{3}$ , which is also very small compared to $d t$ and is therefore ignorable. Finally, we have. $\operatorname{E}[(d z_{t})^{2}]=\operatorname{Var}[d z_{t}]-(\operatorname{E}[d z_{t}])^{2}=d t$ , and it can be shown that?. $\mathrm{Var}[(d z_{t})^{2}]=2(d t)^{2}$ . For $d t$ close to zero, the variance is therefore much less than the mean, so $(d z_{t})^{2}$ can be approximated by its mean. $d t$  

In standard mathematics, the differential of a function $y=g(t,X)$ where $t$ and $X$ are real variables is defined as $\begin{array}{r}{d y=\frac{\partial g}{\partial t}d t+\frac{\partial g}{\partial X}d X}\end{array}$ . When $X$ is an Ito process, (2.13) shows that we haved to add a second-order term..  

# 2.6.7 The geometric Brownian motion  

The geometric Brownian motion is an important example of a diffusion process. A stochastic process $X=(X_{t})_{t\geq0}$ is said to be a geometric Brownian motion if it is a solution to the. stochastic differential equation.  

$$
d X_{t}=\mu X_{t}d t+\sigma X_{t}d z_{t},
$$  

where $\mu$ and $\sigma$ are constants. The initial value for the process is assumed to be positive,. $X_{0}>0$ A geometric Brownian motion is the particular diffusion process that is obtained from (2.6) by inserting $\mu(X_{t},t)=\mu X_{t}$ and $\sigma(X_{t},t)=\sigma X_{t}$  

The expression (2.14) can be rewritten as  

$$
\frac{d X_{t}}{X_{t}}=\mu d t+\sigma d z_{t},
$$  

which is the relative (percentage) change in the value of the process over the next infinitesimally short time interval $[t,t+d t]$ . If $X_{t}$ is the price of a traded asset, then $d X_{t}/X_{t}$ is the rate of return on the asset over the next instant. The constant $\mu$ is the expected rate of return per period, while $\sigma$ is the standard deviation of the rate of return per period. In this context it is often. $\mu$ which is called the drift (rather than $\mu X_{t}$ ) and $\sigma$ which is called the volatility (rather than $\sigma X_{t}$ ). Strictly speaking, one must distinguish between the relative drift and volatility (. $\mu$ and $\sigma$ , respectively) and the absolute drift and volatility ( $\mu X_{t}$ and $\sigma X_{t}$ , respectively). An asset with a constant expected rate of return and a constant relative volatility has a price that follows a geometric Brownian. motion. For example, such an assumption is used for the stock price in the famous Black-ScholesMerton model for stock option pricing, cf. Chapter 12. In the framework of consumption-based. capital asset pricing models it is often assumed that the aggregate consumption in the economy follows a geometric Brownian motion, cf. Chapter 8.  

Next, we will find an explicit expression for $X_{t}$ , i.e. we will find a solution to the stochastic differential equation (2.14). We can then also determine the distribution of the future value of the process. We apply Ito's Lemma with the function $g(x,t)=\ln x$ and define the process $y_{t}=$ $g(X_{t},t)=\ln X_{t}$ . Since  

$$
\frac{\partial g}{\partial t}(X_{t},t)=0,\qquad\frac{\partial g}{\partial x}(X_{t},t)=\frac{1}{X_{t}},\qquad\frac{\partial^{2}g}{\partial x^{2}}(X_{t},t)=-\frac{1}{X_{t}^{2}},
$$  

we get from Theorem 2.5 that  

$$
d y_{t}=\left(0+{\frac{1}{X_{t}}}\mu X_{t}-{\frac{1}{2}}{\frac{1}{X_{t}^{2}}}\sigma^{2}X_{t}^{2}\right)d t+{\frac{1}{X_{t}}}\sigma X_{t}d z_{t}=\left(\mu-{\frac{1}{2}}\sigma^{2}\right)d t+\sigma d z_{t}.
$$  

Hence, the process $y_{t}=\ln X_{t}$ is a generalized Brownian motion. In particular, we have  

which implies that  

$$
y_{t^{\prime}}-y_{t}=\left(\mu-{\frac{1}{2}}\sigma^{2}\right)(t^{\prime}-t)+\sigma(z_{t^{\prime}}-z_{t}),
$$  

$$
\ln X_{t^{\prime}}=\ln X_{t}+\left(\mu-\frac{1}{2}\sigma^{2}\right)(t^{\prime}-t)+\sigma(z_{t^{\prime}}-z_{t}).
$$  

Taking exponentials on both sides, we get  

$$
X_{t^{\prime}}=X_{t}\exp\left\{\left(\mu-\frac{1}{2}\sigma^{2}\right)(t^{\prime}-t)+\sigma(z_{t^{\prime}}-z_{t})\right\}.
$$  

This is true for all $t^{\prime}>t\geq0$ . In particular,  

$$
X_{t}=X_{0}\exp\left\{\left(\mu-{\frac{1}{2}}\sigma^{2}\right)t+\sigma z_{t}\right\}.
$$  

Since exponentials are always positive, we see that $X_{t}$ can only have positive values, so that the.   
value space of a geometric Brownian motion is. $\S=(0,\infty)$  

Suppose now that we stand at time. $t$ and have observed the current value. $X_{t}$ of a geometric Brownian motion. Which probability distribution is then appropriate for the uncertain future value, say at time $t^{\prime}$ ? Since $z_{t^{\prime}}-z_{t}\sim N(0,t^{\prime}-t)$ , we see from (2.15) that the future value. $X_{t^{\prime}}$ (conditional on $X_{t}$ ) will be lognormally distributed. The probability density function for. $X_{t^{\prime}}$ (given $X_{t}$ ) is given by  

$$
f(x)=\frac{1}{x\sqrt{2\pi\sigma^{2}\left(t^{\prime}-t\right)}}\exp\left\{-\frac{1}{2\sigma^{2}\left(t^{\prime}-t\right)}\left(\ln\left(\frac{x}{X_{t}}\right)-\left(\mu-\frac{1}{2}\sigma^{2}\right)\left(t^{\prime}-t\right)\right)^{2}\right\},\quad x>0,
$$  

![](425f447d616cdeb75a538895b1a2c226f1f290e2f69de2589cb1786564914f07.jpg)  
Figure 2.7: Simulation of a geometric Brownian motion with initial value $X_{0}=100$ , relative drift rate $\mu=0.1$ , and a relative volatility of $\sigma=0.2$ and $\sigma=0.5$ , respectively. The smooth curve shows the. trend corresponding to $\sigma=0$ . The simulations are based on 200 subintervals of equal length, and the same sequence of random numbers has been used for the two. $\sigma$ -values.  

and the mean and variance are  

$$
\begin{array}{r l}&{~\mathrm{E}_{t}[X_{t^{\prime}}]=X_{t}e^{\mu(t^{\prime}-t)},}\ &{~\mathrm{Var}_{t}[X_{t^{\prime}}]=X_{t}^{2}e^{2\mu(t^{\prime}-t)}\left[e^{\sigma^{2}(t^{\prime}-t)}-1\right],}\end{array}
$$  

cf. Appendix B.  

Paths can be simulated by recursively computing either  

$$
X_{t_{i}}=X_{t_{i-1}}+\mu X_{t_{i-1}}(t_{i}-t_{i-1})+\sigma X_{t_{i-1}}\varepsilon_{i}{\sqrt{t_{i}-t_{i-1}}}
$$  

or, more accurately,  

$$
X_{t_{i}}=X_{t_{i-1}}\exp\left\{\left(\mu-{\frac{1}{2}}\sigma^{2}\right)\left(t_{i}-t_{i-1}\right)+\sigma\varepsilon_{i}{\sqrt{t_{i}-t_{i-1}}}\right\}.
$$  

Figure 2.7 shows a single simulated sample path for $\sigma=0.2$ and a sample path for $\sigma=0.5$ .For both sample paths we have used $\mu=0.1$ and $X_{0}=100$ , and the same sequence of random numbers.  

We will consider other specific diffusions in later chapters, when we need them. For example, we shall use the Ornstein-Uhlenbeck process defined by  

$$
d X_{t}=\kappa\left(\theta-X_{t}\right)d t+\sigma d z_{t},
$$  

which is the continuous-time equivalent of the discrete-time AR(1) process, and the square root process defined by  

$$
d X_{t}=\kappa\left(\theta-X_{t}\right)d t+\sigma\sqrt{X_{t}}d z_{t}.
$$  

Such processes are used, among other things, to model the dynamics of interest rates.  
