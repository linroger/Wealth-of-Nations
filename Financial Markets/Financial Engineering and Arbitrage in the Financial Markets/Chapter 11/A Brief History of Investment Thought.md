---
tags:
  - '#active_investing'
  - '#algorithmic_trading'
  - '#behavioral_finance'
  - '#efficient_market_hypothesis'
  - '#factor_models'
  - '#index_modeling'
  - '#investment_history'
  - '#portfolio_theory'
  - '#risk_factors'
  - '#value_investing'
---
# 11.1 A BRIEF HISTORY OF INVESTMENT THOUGHT  

In February 1637, a single bulb of a tulip sold for 10 times the annual wage of a skilled artisan. In 1720, investors in the South Sea Company - a chartered monopolist in the trade with the. Western Hemisphere - lost huge amounts amount of money as the company failed. Japanese investors bought the Rockefeller Center in New York for. $\$1$ billion in 1990. In 1995, the Rockefeller Center went bankrupt and sold for. $\$0.5$ billion. Apple Computer traded at $\$13$ in 1996, got up to $\$101.25$ and split 2-for-1 at the height of the tech bubble in June 2000,. then dropped back to $\$14$ in 2002. Then the near dead company reinvented itself with its. revolutionary iPhone, iPad, on-line music, and video delivery. The stock closed at $\$348.48$ on January 14, 2011.  

The first exposition of a rational investment philosophy is Benjamin Graham's Security Analysis (Graham, with Dodd, 1934, 2008) followed by The Intelligent Investor (Graham, with Dodd, 1948, 2003). Graham, the father of value investing, attempted to define what an investment is, provided the first reference to the active and passive style, and drew distinction between the short-term fluctuation and fundamental value. A worthwhile investment was one whose price was lower than the "intrinsic value"' providing a "margin of safety"' The investor's job was to do the right analysis to come up with this intrinsic value, ignore "Mr. Market' offering to buy or sell shares at irrational prices, and wait to buy it at the right price. Graham excoriated corporations for the opacity of the financial reporting and non-dividend payment.  

The challenge to Graham's somewhat active value investing came first with Harry Markowitz's (Modern) Portfolio Theory (Markowitz, 1952), later morphed into the Treynor-- Sharpe-Lintner Capital Asset Pricing Model (CAPM) of the early 1960s (see Treynor, 1961). According to Markowitz, active investing made no sense. Stock markets were efficient valuation machines. Investors had no chance to uncover mispricing or the mispricing has been taken out by the active investors. The best strategy was to rely on the correlation effect to form portfolios of stocks and, better still, to choose only from the portfolios on the efficient frontier. The efficient frontier drawn in the mean-standard deviation space offered the best combinations of risk and return to a risk-averse investor. The CAPM extended this thought by showing that under certain utility and distribution assumptions, investors will do best by allocating their investment dollars between a money market fund and the cap-weighted portfolio of the entire market (rather than other portfolios on the efficient frontier). This has become known as the two-fund separation theorem. Furthermore, if all investors choose to diversify and index, the specific risk has no value. The way stocks are priced in the market is by their degree of systematic risk. It is not total risk (standard deviation), but systematic risk (beta) that enters the expected return that investors demand on the stock and therefore the price they pay for it.  

While the theory was extremely appealing, the practice was not. Tests showed very low $R^{2}\mathrm{s}$ in explaining the stock markets variation; the theory had no time dimension for estimation. Violations of the efficient market hypothesis (EMH), which effectively ruled out active investing as foolish, did not help. Why would you index if you could make money on Mondays or in January? Improvements ranged from theoretical (e.g. include consumption in the definition of the market portfolio) to practical (e.g. time-changing betas, leverage-adjusted betas). Ross (1976) published his arbitrage pricing theory (APT) which introduced the notion of stock portfolios as additional priced systematic risk factors, but more than anything started the search for the missing systematic factors. A California company, BARRA, started providing factor data and portfolio optimization services. Yet the inclusion of observable macroeconomic variables (GDP, inflation, yield curve shape) as risk factors in the models largely failed. It was not until Fama and French (1996) introduced their three-factor model that non-theoretical index modeling took off. In addition, to the market portfolio Fama and French included two firm-specific characteristics: size and book-to-market value. The loadings (betas) on these factors proved to be persistent components of a stock's expected rate of return. Carhart (1997) added one more cross-sectional common factor: momentum. These three- and four-factor specifications delivered super-high $R^{2}\mathrm{s}$ in the regression tests of the models. At the same time, researchers embarked on adding higher moments (co-variance, co-skewness,. co-kurtosis) instead of additional factors to the asset-pricing models with some success..  

However, the bigger parallel thought revolution started back in the late 1970s and the 1980s. The salvos came from experimental psychology. The very basic assumptions of investor rationality began to be questioned. And investors were not rational, but diverse, the representative agent models that allowed generalizing microeconomic behavior and choices to the entire market, started to collapse. Kahneman and Tversky (1979) offered that investors were not risk-averse, but loss-averse. Did mean-variance modeling make sense then? Thaler documented many behavioral inconsistencies with the rationality assumptions throughout the 1980s, and eventually put them into summary books (Thaler, 1991, 1992). The irrationalities came in two streams: common errors people make when processing information and in behavioral biases affecting decision making. Many behavioral finance irrationalities were consistent with the stock market behavior and provided alternative explanations of observed phenomena. Earnings announcement drifts and reversals perhaps had to do with small sample representativeness bias and not information leakage. Underperformance of high P/E stocks could be explained by forecasting errors. Value stock risk premium could be explained by regret avoidance combined with mental accounting as investors shunned unpopular stocks, focused on individual stocks not portfolios, became more risk-averse, and applied higher discount rates to recently underperforming stocks.  

The 1980s also saw a revival of active investing. Value Line continued to be a popular. and widely studied source of stock picks. In 1989, Peter Lynch, Fidelity Magellan's manager,. published his book in which he espoused a very simple philosophy of "investing in what you know" (Lynch, with Rothchild, 1989). He also posed that well-informed observant individuals may be better stock pickers than Wall Street fund managers. They go through their personal lives and business lives and can spot good investments before optimization obsessed fund managers. Lynch's favorite stock picking metric was the PEG (price earnings growth) ratio. The idea is that if a firm is growing, its P/E ratio will grow..  

Many of the behaviors identified by the behaviorists have practical life implications. Framing. can lead to the wrong asset allocation or unconsciously opting out of tax-advantaged accounts. Overconfidence can lead to high turnover and poor returns. Yet it is not clear that if a certain percentage of the population is afflicted with these failings and biases, then the marginal. investor who dictates the prices is subject to them. The counter-revolution in behavioral economics started almost as soon as the behavioral explanations of market phenomena started multiplying, e.g. to include the gloominess of the Nordics due to the lack of sun. Rationality. got a second look. Expanded models based on rationality countered many behavioral claims. Perhaps it is not behavior, but market frictions, taxes, leverage and regulation that dictate price. behavior.  

Whether one subscribes to the behavioral critique or not, the main trend in investment modeling that can certainly be identified is the move away from theory-based models toward. statistical models. Factor and index models do not have to justify utility assumptions; all they need to do is show out-of-sample strategy profits. Momentum can simply be accepted as a fact of life, whether as an informational/microstructure phenomenon, or an outcome of behavioral irrationality. The second trend in developing trading algorithms is the use of accounting data (asset growth, capital expenditure, etc.) superimposed on a three- or four-factor model to extract. the extra "alpha.' The last trend is in "black box" tactical allocation modeling. One overarching development is that of model engines that allow one to combine historical information with some distributional priors or implied inputs and customizing the optimization to one's need.. This is not a neural network -- that idea has largely failed too -- but rather a simpler philosophy that some things are easier estimated (risk) than others (mean returns). The idea goes back to the Black-Litterman model developed at Goldman Sachs (Black and Litterman, 1992). The objective is to combine the historical estimation of the inputs to the portfolio optimization with the realization that the world is changing. In Bayesian statistics that means starting with a prior, superimposing a view and developing a posterior. Asset classes are selected as inputs, and many customized constraints can be imposed. The outcome is an optimized portfolio suited to the client's needs.  
