# Financial Applications of Probability Distributions  

n Chapter 4, we took a look at the fundamentals of probability theory and introduced some distributions. Option theory and indeed much of finance theory is based on the normal distribution as well as the related lognormal distribution; hence, we devote a full chapter to these distributions. In the limit, discrete distributions such as the binomial can be structured to converge to either the normal or lognormal distributions. The reasons for this extensive use of the normal and lognormal distributions are twofold. First, these distributions have only two parameters, because they are completely characterized by the expected value and variance. Second, financial utility is often based on two characteristics: non-satiation and risk aversion. Non-satiation is the notion that people always prefer more money to less. As such, they prefer a higher expected return, so they have a preference for the first moment of the distribution. Risk aversion is the notion that people do not like risk. Hence, they dislike the second moment of the distribution. If people care about only the first two moments, then the normal distribution is appropriate.  

Of course, people may indeed care about higher-order moments. For example, positive skewness is generally a desirable feature of investments. Some financial models are based on skewness preference and skewed distributions. In the first part of the chapter, we will introduce the normal and lognormal distributions. The second part of the chapter refers to a related distribution called the bivariate normal and lognormal. As such, it might be more appropriate to call the single variable versions the univariate normal and lognormal distribution, but this is typically not done. Usually when one uses the phrase normal distribution, one means the univariate normal. This case is the one involving only a single variable. In the second case, the bivariate normal or lognormal, there are two normally distributed variables and they may be correlated.  

# 5.1 THE UNIVARIATE NORMAL PROBABILITY DISTRIBUTION  

The normal probability distribution, known commonly to the layperson as the bell-shaped curve or bell curve, was first identified in the 18th century by Abraham de Moivre (1667–1754). Its mathematical structure was developed by Carl Frederich Gauss (1777–1855) and the curve is often referred to as the Gaussian distribution. Recall the mathematical function that plots the normal curve, called the probability density function or density function for short, is  

$$
n(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\left(\frac{x-\mu}{\sigma}\right)^{2}\big/2},
$$  

where $x$ is the value of the random variable, $\mu$ is its expected value, and $\sigma$ is its standard deviation.1 We use the lowercase $n()$ for the density function to remind us that it is the normal distribution. The variable has values that range from $-\infty$ to $+\infty$ .  

Any normally distributed random variable can be expressed as a standard normal random variable by subtracting its expected value and dividing by its standard deviation. This standardized normal variable is often referred to with the letter $z$ and its density is written as  

$$
n(z)={\frac{1}{\sqrt{2\pi}}}e^{-z^{2}/2}.
$$  

A normal distribution can apply to any random variable, but this is a special case that we often use that is called the standard normal, which has an expected value of zero and a variance of 1. For example, a normally distributed random variable with an expected value of 6 and a standard deviation of 3 can be modeled with a standard normal random variable with an expected value of 0 and a standard deviation of 1. If one observed a value of the random variable of 8, we would convert it to a standard normal by subtracting the expected value of 6 and dividing by the standard deviation of 3 to obtain $(8-6)/3=2/3$ . Alternatively, if we generate a standard normal random variable with value 2/3, we can convert it to the random variable we seek to model by multiplying by 3 and adding 6 to obtain $(2/3)^{*}3+6=8$ .  

The density function gives only the height of the curve. The actual probability of a random variable lying within a particular range is provided by the distribution function, which is the cumulative density. The mathematical specification for the cumulative density function for a standard normal is  

$$
N(z)=\int_{-\infty}^{z}\frac{1}{\sqrt{2\pi}}e^{-x^{2}/2}d x.
$$  

This equation is interpreted as the probability that a standard normal variable will be less than $z$ . It is sometimes written as $\Pr(x\leq z)$ or simply $N(z)$ . The probability is the area under the curve. The total area under the curve, that is, the integral from $-\infty$ to $+\infty$ , is 1.0. Thus $N(\infty)=1$ and $N(-\infty)=0$ . The probability that a standard normal variable will lie between $a$ and $b$ $(a<b)$ is given as $N(b)-N(a)$ . With any continuous variable, it is impossible to speak of the probability of obtaining a specific value such as the probability that $z=a$ . The probability of observing any one value in a continuous distribution is zero. Only the probability over a range can be determined. Thus, the expressions $\Pr(z\leq a)$ and $\operatorname*{Pr}(z<a)$ are equivalent.  

Calculation of the probability for a particular range involves the evaluation of the previous integral. It is well known that the distribution function for the normal probability cannot be integrated by standard mathematical means. Instead, estimation techniques must be used. Tables for the function are widely available and found in nearly every statistics book. Fortunately, there are several other excellent and simple means of computing the normal probability.  

It is a general rule that any well-behaved mathematical function with derivatives that exist up to a given order can be approximated by a polynomial function of that order. There are many such approximations of the normal probability, most of which are provided in Abramowitz and Stegun (1972). Probably the most widely used is the following:  

$$
N(z)=1-n(z)\binom{0.31938153k-0.356563782k^{2}+1.781477937k^{3}}{-1.821255978k^{4}+1.330274429k^{5}},
$$  

where $k=1/(1+0.2316419z)$ and $n(z)=\left(1/\sqrt{2\pi}\right)\exp\left(-z^{2}/2\right).$ . If $z<0$ , the fact that the curve is symmetric enables us to obtain $N(z)$ as $1-N(z)$ . This function is known to be accurate to at least four digits.  

In addition, the Excel function $\scriptstyle\cdots=\mathrm{normsdist}(\mathbf{x})^{\prime\prime}$ where $\mathbf{x}$ is a value or cell reference can be used with reasonable accuracy. Table 5.1 provides a detailed table created with this Excel function and is useful when manually estimating values from a standard normal cumulative distribution function.  

To use this table, suppose we wish to find the probability of observing a value less than 1.3520. This value is found by looking up 1.3 in the left column and moving over to the 0.05 column. We see that $N(1.35)=0.911492$ . This table provides values to six decimal places. We simply round at the 0.0025 and 0.0075. Thus, in this case, 1.352 rounds down to 1.35. Now suppose we wish to find $N(-0.5230)$ . Because this table provides negative values, we simply find $N(-0.525)$ as we round up in absolute value to the next 0.005 increment. Thus, $N(-0.525)=0.299792$ . Table 5.1 is useful for classroom work as the chance for serious rounding errors is minimal. Note that $N(0.0)=0.5$ , meaning that half of the area under the curve is to the left of zero. In this table, however, there are two cells with $0.5\left[N(0.0)\right.$ and $N(-0.0)]$ . In the row with $-0.0$ , the values are moving more negative, whereas in the row with 0.0, the values are moving more positive.  

In finance, one of our primary interests is in the distribution of financial market returns. When a variable is normally distributed, statistical analysis and testing is much easier. The distribution of daily returns on the S&P 500 from a recent 66-year period is depicted in Figure 5.1. There are 16,858 returns, so the breakdowns are relatively dense. The figure does give a modest appearance of a normal distribution, but there are some troubling factors. There are two returns of more than $10\%$ and one of less than $-20\%$ . Let us try to determine the likelihood that such returns would occur on a given day in a normal distribution.  

The average daily return is 0.000338, and the standard deviation is 0.009666. For a return of $-20\%$ , the $z$ -statistic is $(-0.2-0.000338)/0.009666=-21.2099.$ 2 Thus, a return of $-20\%$ in a day is more than 21 standard deviations to the left. The probability of this occurring is $3.8724\mathrm{e}{-}100$ , which is about $1.03295\mathrm{e}+97$ years of trading.3 On the upside, the highest return is more than 11 standard deviations above the mean, a probability also extremely small. These returns are so extreme that they cast doubt about whether the normal distribution is appropriate.  

Normal probability theory also says that only about $0.3\%$ of all returns should be more than $+/-$ three standard deviations of the mean. With $16,858\mathrm{S}\&\mathrm{p}\ 500$ returns, we should expect that $0.003(16,858)=50.57$ , or about 51 returns above and below three standard deviations. In fact, there are 112 returns above and 123 below, for a total of 235.  

TABLE 5.1 Standard Normal Cumulative Distribution Function Table   


<html><body><table><tr><td colspan="13">Values for N(d), given d: Rows give first decimal of d and columns give second and third decimals</td></tr><tr><td>d</td><td>0.000</td><td></td><td>0.005</td><td>0.010</td><td>0.015 0.020</td><td>0.025</td><td>0.030</td><td>0.035</td><td>0.040</td><td>0.045</td><td>0.050</td><td>0.055</td><td>0.060</td><td>0.065</td><td>0.070</td><td>0.075</td><td>0.080</td><td>0.085</td><td>0.090</td><td>0.095</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>2970</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.001418 0.001395 0.001372</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>2.60.004661</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>6</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>1.2 0.115070 0.114102 0.113139 0.112183 0.111232</td><td></td><td></td><td></td><td>1</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.028800150866000060205060</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></table></body></html>  

<html><body><table><tr><td>0.03 0. 0</td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>1</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>7</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>0</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr></table></body></html>  

![](98aaeb85032aef1fe4d65ddb804c9c6a79afe23ffe13da23ed5fb766f06676e1.jpg)  
FIGURE 5.1 S&P 500 Daily Returns  

So indeed, the normal distribution is not a perfect fit. We should not have expected as much, but that does not mean that it cannot serve as a useful approximation. Now, however, let us consider a closely related alternative.  

Recall the discretely compounded rate of return, $R_{t}^{d}$ , expresses the relationship between asset prices at $t-1$ and $t$ is  

$$
S_{t-1}\left(1+R_{t}^{d}\right)=S_{t}.
$$  

Hence, the return is calculated as  

$$
R_{t}^{d}=\left(\frac{S_{t}}{S_{t-1}}\right)-1.
$$  

Some researchers have argued that the use of log or continuously compounded returns can reduce the nonnormality. The log return, $R_{t}^{c}$ , expresses the relationship between a variable at two points in time as it grows continuously:  

$$
S_{t-1}e^{R_{t}^{c}}=S_{t}.
$$  

Hence, it is calculated as  

$$
R_{t}^{c}=\ln\left(\frac{S_{t}}{S_{t-1}}\right).
$$  

![](7baebc9d2044241a2205c9cc1063b79fb0c76ef6ead1b85f4f0024ab91dfbb2f.jpg)  
FIGURE 5.2 S&P 500 Log Returns  

Some researchers believe that log returns are closer to being normally distributed. This point is partially true but only by a small amount. Log returns are slightly smaller than regular returns, thereby pulling in the largest positive returns but by reducing returns, they lower the largest negative returns. For example, the largest positive return of $11.58\%$ (October 13, 2008) has a log equivalent of $10.96\%$ . The largest negative return, $-20.47\%$ (October 19, 1987), has a log equivalent of $-22.90\%$ . Both returns are lower and not enough to eliminate the simple fact that there are far too many extreme returns for a normal distribution. Figure 5.2 illustrates the same data using log returns. As you can see, there is not much difference.  

# 5.2 CONTRASTING THE NORMAL WITH THE LOGNORMAL PROBABILITY DISTRIBUTION  

Based on properties of the lognormal distribution, if $S_{t}=S_{t-1}e^{R_{t}^{c}}$ and $R_{t}^{c}$ is normally distributed, then we know $S_{t}$ is lognormally distributed. Recall if $x$ has a lognormal distribution, then the PDF is  

$$
\lambda(x)=\frac{1}{x\sigma\sqrt{2\pi}}e^{-\left(\frac{[\ln(x)-\mu]^{2}}{2\sigma^{2}}\right)}.
$$  

Again, the range of a lognormally distributed variable is $0<x<+\infty$ . Importantly, zero is not included.  

Recall from Chapter 4, the $n^{t h}$ noncentral moment is defined as ${\mu_{n}}^{\prime}(x)=E(x^{n})$ and the $n^{t h}$ central moment is defined as $\mu_{n}(x)=E[(x-\mu)^{n}]$ . Thus, subtracting a constant term from a random variable affects only the mean, not the higher central moments, such as variance, skewness, and kurtosis. We denote the first difference or dollar profit and loss as  

$$
\Delta S_{t}=S_{t}-S_{t-1}.
$$  

There are many finance applications where we are interested in dollar gains and losses. For example, company earnings are simply revenues less expenses. Because earnings can be zero or negative, we do not want model earnings with a distribution that does not admit zero or negative numbers.4 Because the uncertainty at time $t-1$ is solely the instrument price or value at time $t$ , the expected value is  

$$
E(\Delta S_{t})=E(S_{t})-S_{t-1}.
$$  

The higher central moments are simply  

$$
\operatorname{var}(\Delta S_{t})=\operatorname{var}(S_{t}),
$$  

$$
S k e w(\Delta S_{t})=S k e w(S_{t}),\mathrm{and}
$$  

$$
K u r t o s i s(\Delta S_{t})=K u r t o s i s(S_{t}).
$$  

Several important insights can be gained when we assume a lognormal distribution. First, the continuously compounded rate of return follows a normal distribution. Second, the normalized skewness of the rate of return should be zero, but the normalized skewness of the first difference should be positive. Third, the normalized kurtosis of the rate of return should be 3, but the normalized kurtosis of the first difference should be greater than 3.5  

When building quality valuation models, it is important to understand empirical properties of financial data. Here we briefly review empirical data related to two exchangetraded funds (ETFs), the S&P 500 ETF (SPY) and the Technology Sector ETF (XLK), as well as Apple stock (AAPL). We explore five years of daily data. Figure 5.3 provides plots of the time series rates of return and first differences. To facilitate comparison, the first differences are based on an assumed $\$1$ investment at the beginning of the period. For ease of comparison, we set the $y.$ -axis to be the same for all the return plots. Likewise, we set the y-axis to be the same for all the first difference plots. Intuitively, we would expect that an individual stock would be more risky than a portfolio of stocks within its sector. Further, we would expect the technology sector ETF would be more risky than a broad-based index such as SPY. The pattern of standard deviations is consistent with our intuition. Outside of basic distributional properties, it is unclear how skewness and kurtosis would behave. Interestingly, all skewness measures are negative rather than zero or positive as the distributional assumptions would imply. Further, the skewness measures are similar between returns and first differences. We would have expected the first difference skewness to be positive or at least less negative than returns. All kurtosis measures are greater than three with daily first differences being slightly lower.  

![](4f4bef1e40ba03e72623327334dcda3f329892d93877d3d5dd20fd21c375623c.jpg)  
FIGURE 5.3 Time Series of Daily Returns and First Differences  

Figure 5.4 provides histograms of this same data along with the corresponding normal distribution probability density function. The histograms are more spread out as we move from SPY to XLK to AAPL. The patterns are very similar when comparing returns and first differences as well as consistent with the previous univariate analysis.  

![](59624da95245d3bed121e3fa1b624e17a81ab991688cb60a48074954a183008a.jpg)  
FIGURE 5.4 Histogram of Daily Returns and First Differences  

# 5.3 BIVARIATE NORMAL PROBABILITY DISTRIBUTION  

Suppose now that we have two normally distributed random variables, $x$ and $y$ . The expected values are $\mu_{x}$ and $\mu_{y}$ and the standard deviations are $\sigma_{x}$ and $\sigma_{y}$ . For bivariate normally distributed random variables, the conditional expected values of $y$ and $x$ are linearly related, as indicated by the following:  

$$
E(y|x_{a})=\mu_{y}+\rho\left(\frac{\sigma_{y}}{\sigma_{x}}\right)(x_{a}-\mu_{x}),
$$  

where $\rho$ is the correlation between $y$ and $x$ . This statement says that if the value of $x$ is known, the expected value of $y$ is given by the right-hand-side expression. This expectation of $y$ is called the conditional expected value of $y$ , given $x_{a}$ . The terms $\mu_{y}$ and $\mu_{x}$ are the unconditional expected values. They are our best estimates of the expected values of $y$ or $x$ , given that we know nothing about the value of the other. If $x$ and $y$ are linearly related, then the correlation between $x$ and $y$ can be used to make a better prediction of $y_{i}$ , given that we know the current value of $x$ , which is $x_{a}$ . If $y$ and $x$ are related in this manner, then the joint distribution of $y$ and $x$ is bivariate normal. The conditional variance of $y$ is related to its unconditional variance by the formula  

$$
\sigma_{y|x}^{2}=\sigma_{y}^{2}(1-\rho^{2}).
$$  

The probability density function for the bivariate normal is  

$$
\begin{array}{l}{f(x,y,\rho)=\displaystyle\frac{1}{2\pi\sigma_{x}\sigma_{y}\sqrt{1-\rho^{2}}}}\\ {\displaystyle~\exp\left[-\displaystyle\frac{1}{2}\left(\frac{\left(\left(x-\mu_{x}\right)/\sigma_{x}\right)^{2}-2\rho(\left(x-\mu_{x}\right)/\sigma_{x}\right)\left(\left(y-\mu_{y}\right)/\sigma_{y}\right)+\left(\left(y-\mu_{y}\right)/\sigma_{y}\right)^{2}}{1-\rho^{2}}\right)\right].}\end{array}
$$  

The distribution function or cumulative bivariate normal probability is  

$$
\begin{array}{l}{\displaystyle\operatorname*{Pr}(x\leq x_{a},y\leq y_{b}\vert\rho)=\frac{1}{\sigma_{x}\sigma_{y}}\displaystyle\int_{-\infty}\displaylimits^{\frac{x_{a}-\mu_{x}}{\sigma_{x}}}\displaystyle\int_{-\infty}\frac{y_{b}-\mu_{y}}{2\pi\sqrt{1-\rho^{2}}}}\\ {\displaystyle\exp\left[-\frac{1}{2}\left(\frac{k^{2}-2\rho k j+j^{2}}{1-\rho^{2}}\right)\right]d k d j.}\end{array}
$$  

Because each variable $x$ and $y$ is individually normally distributed, each can be transformed or normalized into a standard normal random variable, which we shall call $z_{1}$ and $z_{2}$ , by the relationships,  

$$
z_{1}=\frac{x-\mu_{x}}{\sigma_{x}},~z_{2}=\frac{y-\mu_{y}}{\sigma_{y}}.
$$  

The standard normal bivariate density is then  

$$
f(z_{1},z_{2},\rho)=\frac{1}{2\pi\sqrt{1-\rho^{2}}}\exp\left[-\frac{1}{2}\left(\frac{z_{1}^{2}-2\rho z_{1}z_{2}+z_{2}^{2}}{1-\rho^{2}}\right)\right].
$$  

Figure 5.5 illustrates the standard normal bivariate density in three-dimensional space.  

The following relationships are useful when dealing with the bivariate normal probability distribution. Let $N(x)$ be the (univariate) normal probability for a variable $x$ and $N_{2}(x,y;\rho)$ be the bivariate normal probability for the variables $x$ and $y_{;}$ , which can be normalized or not, with correlation $\rho$ . Then, the following are a handful of useful rules.  

$$
\begin{array}{c}{{N_{2}(x,y;\rho)=N_{2}(y,x;\rho)}}\\ {{{}}}\\ {{N_{2}(-x,y;\rho)+N_{2}(x,y;-\rho)=N(y)}}\\ {{{}}}\\ {{N_{2}(x,y;\rho)-N_{2}(-x,-y;\rho)=N(x)+N(y)-1.0.}}\end{array}
$$  

Computation of the bivariate normal probability is quite challenging, but an analytic approximation developed by Drezner (1978) is often used and gives a high degree of accuracy.6 Using that approximation, let us work a problem involving bivariate standard normal random variables. An Excel routine based on this technique is in Appendix 5A. Let $x=0.74$ , $y=-1.13$ , and $\rho=0.32$ . We wish to know $\operatorname*{Pr}(x\leq0.74$ , $y\le-1.13|0.32)$ . The univariate probabilities as obtained from Excel’s $\scriptstyle=$ normsdist() function are $N(0.74)=0.7704$ and $N(-1.13)=0.1292$ . The bivariate normal probability is $N_{2}(0.74,-1.13;0.32)=0.1171$ . Let us check out the above relationships:  

![](c905d7533f0a2f4d829d73241f535b01a931f882854d05d964c0166dec4c26a7.jpg)  
FIGURE 5.5 Bivariate Normal Density  

$$
N_{2}(0.74,-1.13,0.32)=0.1171=N(-1.13,0.74,0.32)=0.1171
$$  

$$
N_{2}(-0.74,-1.13,0.32)=0.0529,N_{2}(0.74,-1.13,-0.32)=0.0763
$$  

$$
0.0529+0.0763=0.1292=N(-1.13)
$$  

$$
N_{2}(0.74,-1.13,0.32)=0.1171,N_{2}(-0.74,1.13,0.32)=0.2175
$$  

$$
0.1171-0.2175=-0.1004
$$  

$$
N(0.74)=0.7704,N(-1.13)=0.1292
$$  

Some special cases are worth noting. If either of the values $x$ or $y$ is infinite, then the bivariate probability reverts to the univariate probability. For example, $\Pr(x\leq a,y\leq$ $\infty|\rho)=\operatorname*{Pr}(x\leq a)$ . This is because of the condition that $y\le\infty$ has no effect because its pr|obability is 1.0. This fact, of course, also holds if the variables are reversed. If $\rho=0$ , then the bivariate probability is the product of the two univariate probabilities of $x$ and $y$ , that is, $\operatorname*{Pr}(x\leq a,y\leq b|\rho=0)=N(a)N(b)$ . This result reflects the fact that the joint probability of two independe|nt random variables is the product of the marginal probabilities. A few other special relationships hold when $\rho=1$ , but these conditions are rarely observed. You can look these up in Abramowitz and Stegun (1972).  

The bivariate normal probability generalizes into a multivariate normal probability. In finance, one occasionally sees the trivariate normal probability and there are techniques for estimating it, which involve simplification of the relationships among univariate, bivariate, and trivariate densities. For the most part, however, computation of these high-order integrals is extremely time-consuming. Monte Carlo simulation is a good way of getting these results.  

# 5.4 THE BIVARIATE LOGNORMAL PROBABILITY DISTRIBUTION  

Again if $S_{t}=S_{t-1}e^{R_{t}^{c}}$ and $R_{t}^{c}$ is normally distributed, then we know $S_{t}$ is lognormally distributed. In finance, we are often interested in a portfolio of instruments such as stock holdings. Unfortunately, the sum of lognormally distributed random variables does not follow any known distribution. One important property of the normal distribution is that the sum of normally distributed random variables is itself normally distributed. Thus, in practice, it is dramatically easier to assume the underlying instrument prices are normally distributed, an issue we address in Chapter 12.  

Figure 5.6 illustrates a simulation of 1,000 draws from a bivariate lognormal distribution, with normal mean 0, variance 1, and correlation 0. Note that the bivariate lognormal lower bound is zero for both $x$ and $y$ , but it is non-inclusive. Specifically, an outcome of zero did not occur because it is not possible with the lognormal distribution. Therefore, one advantage of the lognormal distribution is that negative values are not possible. Closely related, one disadvantage of the lognormal distribution is that zero values are also not possible.  

![](c1f617fe7ac264378720851d8d1a49075d4398fab0efc59e7453d46441819707.jpg)  
FIGURE 5.6 Bivariate Lognormal Simulation  

# 5.5 RECAP AND PREVIEW  

In this chapter, we reviewed the univariate normal probability distribution and took a look at the historical returns on the $\$80$ to see how well the distribution fits the data. We also examined the bivariate normal probability distribution, which can apply when there are two random variables.  

In Chapter 6, we take a brief review of the basic concepts in valuing risky assets and derivatives.  

# APPENDIX 5A  

# An Excel Routine for the Bivariate Normal Probability  

The two variables are identified as $a$ and $b$ and the correlation is rho. Enter them into three cells, which for the sake of illustration will be $A1,B1$ , and C1. Then in a separate cell, type the function $={\mathrm{bivar}}(A1,B1,C1)$ . The code, which is presented next, should be entered using the Visual Basic for Applications feature of Excel. Choose the Developer tab. Then choose Visual Basic. Then Insert, then Module. You will then have a blank space on which to enter the following code.  

If you wish to receive an electronic copy of this code, please email your request to Don Chance, dchance@lsu.edu.  

# VB Code:  

Sub biv1(az, bz, rhoz, bprob)   
'Subroutine used to compute bivariate normal probability   
Dim bp1, bp2, bp3, bp4, prob   
bp1 $\mathbf{\sigma}=\mathbf{\sigma}$ phiz(az, bz, rhoz)   
bp2 $\mathbf{\sigma}=\mathbf{\sigma}$ Application.NormSDist(az) - phiz(az, -bz, -rhoz)   
bp3 $\mathbf{\sigma}=\mathbf{\sigma}$ Application.NormSDist(bz) - phiz(-az, bz, -rhoz)   
bp4 $\mathbf{\sigma}=\mathbf{\sigma}$ Application.NormSDist(az) $^+$ Application   
.NormSDist(bz) - 1 $^+$ phiz(-az, -bz, rhoz)   
bprob $\mathbf{\Omega}=\mathbf{\Omega}0!\mathbf{\Omega}$   
11 If rhoz $\mathit{\Theta}=\mathit{\Theta}0$ Then bprob $\mathbf{\sigma}=\mathbf{\sigma}$ Application.NormSDist(az) $\star$ Application   
.NormSDist(bz) Else GoTo 12   
GoTo 55   
12 If az $\begin{array}{r}{\mathrm{~\boldmath~\omega~}<=0!}\end{array}$ And bz $\begin{array}{r}{\mathrm{~\boldmath~\omega~}<=\mathrm{~\boldmath~0~!~}}\end{array}$ And rhoz $\scriptstyle<=0$ Then bprob $\mathbf{\sigma}=\mathbf{\sigma}$ bp1 Else GoTo 13   
GoTo 55   
13 If az $\begin{array}{r}{\mathrm{~\boldmath~\omega~}<=\mathrm{~\boldmath~0~!~}}\end{array}$ And bz $\scriptstyle>=0$ And rhoz $\scriptstyle>=0$ Then bprob $\mathbf{\Sigma}=\mathbf{\Sigma}$ bp2 Else GoTo 14   
GoTo 55   
14 If az $\scriptstyle>=0$ And bz $\scriptstyle<=0$ And rhoz $\scriptstyle>=0$ Then bprob $\mathbf{\sigma}=\mathbf{\sigma}$ bp3 Else GoTo 15   
GoTo 55   
15 If az $\scriptstyle>=0$ And bz $\scriptstyle>=0$ And rhoz $\scriptstyle<=0$ Then bprob $\mathbf{\sigma}=\mathbf{\sigma}$ bp4 Else GoTo 16   
16 GoTo 55   
55 End Sub   
Sub biv2(az, bz, rhoz, bprob)   
'Subroutine used to compute bivariate normal probability   
Dim signa, signb, rhoab, rhoba, Delta, probab, probba   
If az $\scriptstyle>=0$ Then signa $\mathbf{\Psi}=\mathbf{\Psi}_{1}$ Else signa $\begin{array}{r l}{\mathbf{\Psi}=}&{{}-\mathbf{1}}\end{array}$   
If bz $\scriptstyle>=0$ Then signb $\mathbf{\Psi}=\mathbf{\Psi}_{1}$ Else signb $\begin{array}{r l}{\mathbf{\Psi}=}&{{}-\mathbf{1}}\end{array}$   
rhoab $\mathbf{\sigma}=\mathbf{\sigma}$ (rhoz \* az - bz) $\star$ signa $/\texttt{S q r}(\texttt{a z}\texttt{2-2}\texttt{\star}\texttt{r h o z}\texttt{\star}\texttt{a z}\texttt{\star b z}+\texttt{b z}\texttt{\^{\star}}2)$   
rhoba $\mathbf{\sigma}=\mathbf{\sigma}$ (rhoz \* bz - az) $\star$ signb / Sqr(az ˆ 2 - 2 \* rhoz \* az \* bz + bz ˆ 2)   
Delta $\mathbf{\sigma}=\mathbf{\sigma}$ (1 - signa $\star$ signb) / 4   
Call biv1(az, 0, rhoab, probab)   
Call biv1(bz, 0, rhoba, probba)   
bprob $\mathbf{\sigma}=\mathbf{\sigma}$ probab $^+$ probba - Delta   
End Sub   
Function bivar(az, bz, rhoz)   
'Function to compute bivariate normal probability   
Dim bprob   
If az \* bz $\star$ rhoz > 0 Then GoTo 20   
Call biv1(az, bz, rhoz, bprob)   
GoTo 56   
20 Call biv2(az, bz, rhoz, bprob)   
56 bivar $\mathbf{\sigma}=\mathbf{\sigma}$ bprob   
End Function   
Function phiz(aa, bb, rhoo)   
'sub-function to compute bivariate normal probability   
Dim a1, b1, fsum, i, j, f, phizz   
Static w(5), $\mathbf{x}\left(5\right)$   
w(1) = 0.24840615: x(1) = 0.10024215   
w(2) = $0.39233107:~\mathbf{x}\left(2\right)~=~0.48281397$   
w(3) = $\begin{array}{c c c}{0.21141819:}&{\mathbf{x}\left(3\right)}&{=}&{1.0609498}\end{array}$   
w(4) = 0.03324666: x(4) = 1.7797294   
w(5) = 0.00082485334: x(5) = 2.6697604   
a1 = aa / Sqr(2 \* (1 - rhoo ˆ 2))   
b1 $\mathbf{\sigma}=\mathbf{\sigma}$ bb / Sqr(2 \* (1 - rhoo ˆ 2))   
fsum $\mathit{\Theta}=\mathit{\Theta}0$   
For $\mathrm{~\\\~i~}=\mathrm{~1~}$ To 5 For $\begin{array}{l l l}{{\displaystyle{\dot{\mathrm{~\boldmath~{~\cal~j~}~}}}}}&{{=}}&{{1}}\end{array}$ To 5 f = Exp(a1 \* (2 \* x(i) - a1) + b1 \* (2 \* x(j) - b1) + 2 \* rhoo \*   
$({\bf x}(\mathrm{i})\mathrm{~\ensuremath~{~-~}~}{\bf a}\mathrm{1}$ ) $\star$ (x(j) - b1)) fsum $\mathbf{\Sigma}=\mathbf{\Sigma}$ fsum $^+$ w(i) \* w(j) \* f Next j   
Next i   
phizz $\mathbf{\sigma}=\mathbf{\sigma}$ 0.31830989 \* Sqr(1 - rhoo ˆ 2) \* fsum   
phiz $\mathbf{\Sigma}=\mathbf{\Sigma}$ phizz   
End Function  

# QUESTIONS AND PROBLEMS  

1 Based on Table 5.1, identify the following standard normal cumulative distribution values: 0.0, 0.58, −0.58, 1.65, and $-1.65$ . Explain your results. Based on Figure 5.2 and subsequent analysis, identify the key insight that is revealed.   
3 Suppose a stock trading at 75 is estimated to have an annualized, continuously compounded mean rate of return of $12\%$ and a corresponding standard deviation of $45\%$ . Assume these returns are normally distributed. Estimate the expected change in the stock price in one year as well as the stock price standard deviation, normalized skewness, and normalized kurtosis.   
4 Based solely on visual inspection of Figure 5.3, what conclusion can be drawn from comparing the time series of daily rates of return with daily first differences for the broad index ETF (SPY), the technology sector ETF (XLK), and Apple (AAPL)?   
5 Based solely on visual inspection of Figure 5.4, what conclusion can be drawn from comparing the frequency distribution of daily rates of return with daily first differences for the broad index ETF (SPY), the technology sector ETF (XLK), and Apple (AAPL)?  

# NOTES  

1. Prior to the introduction of the euro in 1999, the German currency was called the deutschemark. A 10-deutschemark note contained a picture of Gauss and his famous curve as well as the formula. It is likely the only piece of currency in history to contain an equation.   
2. This value was calculated on a spreadsheet and is more precise than if you did it by hand.   
3. By comparison, astronomers estimate the age of the universe at about 4.5 billion years, or much shorter than the expected frequency of a one-day return of less than $-20\%$ under a normal distribution of asset returns.   
4. There are many other examples, such as dollar differences between purchases and sales, spreads between commodities, as well as spreads across different contract expirations.   
5. Recall from Chapter 4 that the normalization process converts the skewness and kurtosis to unitless numbers by dividing by functions of variance or $\mathrm{var}^{2/3}$ and var2, respectively. The normal distribution has normalized skewness of 0 and normalized kurtosis of 3.   
6. See Chance and Ag˘ca (2003) for an examination of the speed and accuracy of bivariate normal approximation routines for option pricing.  